{
    "model": "mistralai/Mistral-7B-v0.1",
    "dataset": "openai/gsm8k",
    "device": "cuda",
    "experiment_name": "all_baseline_mistral",
    "tokens_per_response": 30,
    "prompting_technique": "baseline",
    "top_p": 0.95
}