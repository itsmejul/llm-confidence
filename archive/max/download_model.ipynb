{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b666428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from huggingface_hub import HfFolder, whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b559c5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.3\n"
     ]
    }
   ],
   "source": [
    "print(transformers.__version__) #has to be at least 4.51.3 for model GLM-4-Z1-9B-0414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e36f6034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = str(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74dd9bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logged in as M00nl8tshad0w\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "HfFolder.save_token(hf_token)\n",
    "user = whoami()\n",
    "print(f\"logged in as {user[\"name\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39e41692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name, local_dir=\"./models/llama3_70b\"):\n",
    "    if os.path.exists(local_dir):\n",
    "        print(f\"Loading model from local directory: {local_dir}\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(local_dir)\n",
    "        model = AutoModelForCausalLM.from_pretrained(local_dir, device_map=\"auto\", torch_dtype=\"auto\")\n",
    "    else:\n",
    "        print(f\"Local directory not found. Downloading model '{model_name}' from Hugging Face Hub...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=\"auto\")\n",
    "\n",
    "        os.makedirs(local_dir, exist_ok=True)\n",
    "        tokenizer.save_pretrained(local_dir)\n",
    "        model.save_pretrained(local_dir)\n",
    "        print(f\"Model downloaded and saved locally to: {local_dir}\")\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99e3eb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local directory not found. Downloading model 'Qwen/Qwen3-8B' from Hugging Face Hub...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd4dd6b4cd042a29dab00c39bb2257e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74053ef4cd641218c09d3dffa3512d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f213d4d58c4260b4a613e1325eb093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/3.19G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db55f2bcb79461a98595d6e007a9759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8b8483a702403e989071544103d468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03415b9a5db941a4b41dfe0f1325ffb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3dc93efb6347c89316e8c4c3056f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "/home/max/Studium/Leipzig/Semster6/Math_and_ML/math-ml/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3391: UserWarning: Attempting to save a model with offloaded modules. Ensure that unallocated cpu memory exceeds the `shard_size` (5GB default)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbbf7c6f47946e68b594364e98e721d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded and saved locally to: /home/max/Studium/Leipzig/Semster6/Math_and_ML/hf_models/Qwen/Qwen3-8B\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Qwen2TokenizerFast(name_or_path='Qwen/Qwen3-8B', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       " \t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151665: AddedToken(\"<tool_response>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151666: AddedToken(\"</tool_response>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151667: AddedToken(\"<think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151668: AddedToken(\"</think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " }\n",
       " ),\n",
       " Qwen3ForCausalLM(\n",
       "   (model): Qwen3Model(\n",
       "     (embed_tokens): Embedding(151936, 4096)\n",
       "     (layers): ModuleList(\n",
       "       (0-35): 36 x Qwen3DecoderLayer(\n",
       "         (self_attn): Qwen3Attention(\n",
       "           (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "           (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "           (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "           (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "           (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "           (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "         )\n",
       "         (mlp): Qwen3MLP(\n",
       "           (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "           (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "           (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "           (act_fn): SiLU()\n",
       "         )\n",
       "         (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "         (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "       )\n",
       "     )\n",
       "     (norm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "     (rotary_emb): Qwen3RotaryEmbedding()\n",
       "   )\n",
       "   (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       " ))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = \"Qwen/Qwen3-8B\"\n",
    "load_model(model_name = MODEL_PATH, local_dir=\"/home/max/Studium/Leipzig/Semster6/Math_and_ML/hf_models/Qwen/Qwen3-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e844c8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
