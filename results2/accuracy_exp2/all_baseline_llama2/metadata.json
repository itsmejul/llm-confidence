{
    "model": "meta-llama/Llama-2-7b-hf",
    "dataset": "openai/gsm8k",
    "device": "cuda",
    "experiment_name": "all_baseline_llama2",
    "tokens_per_response": 30,
    "prompting_technique": "baseline",
    "top_p": 0.95
}